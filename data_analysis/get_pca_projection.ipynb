{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of PCA/LDA\n",
    "\n",
    "What can we learn from PCA of dataset before and after feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in range(1,6):\n",
    "    matOut = {}\n",
    "    matFile = 'S' + str(subject) + '_pca.mat'\n",
    "    \n",
    "    # load subject data\n",
    "    emgHD = sio.loadmat('./hw_encode/S' + str(subject) + 'E1.mat')['emgHD']\n",
    "    \n",
    "    # collect all features, ngrams, and labels\n",
    "    numGest, numTrial = emgHD.shape\n",
    "    numCh = emgHD[0][0][3].shape[1]\n",
    "    numEx = emgHD[0][0][3].shape[0]\n",
    "    N = 5\n",
    "    features = np.empty((numCh*N,0))\n",
    "    featureLabels = np.empty(0)\n",
    "    for i in range(numGest):\n",
    "        for j in range(numTrial):\n",
    "            x = emgHD[i][j][3].T\n",
    "            f = np.empty((0,numEx-N+1))\n",
    "            for n in range(N):\n",
    "                f = np.concatenate((f,x[:,n:(80-N+1+n)]),axis=0)\n",
    "            features = np.concatenate((features,f),axis=1)\n",
    "            featureLabels = np.concatenate((featureLabels,i*np.ones(numEx-N+1)))\n",
    "      \n",
    "    # arrange data into a pandas dataframes for interface with sklearn\n",
    "    featCols = ['feature' + str(i) for i in range(features.shape[0])]\n",
    "    featDF = pd.DataFrame(features.T,columns=featCols)\n",
    "    \n",
    "    dim = emgHD[0][0][4].shape[0]\n",
    "    numEx = emgHD[0][0][4].shape[1]\n",
    "    ngrams = np.empty((dim,0))\n",
    "    ngramLabels = np.empty(0)\n",
    "    for i in range(numGest):\n",
    "        for j in range(numTrial):\n",
    "            ngrams = np.concatenate((ngrams,emgHD[i][j][4]),axis=1)\n",
    "            ngramLabels = np.concatenate((ngramLabels,i*np.ones(numEx)))\n",
    "        \n",
    "    # arrange data into a pandas dataframes for interface with sklearn\n",
    "    hvCols = ['hv' + str(i) for i in range(ngrams.shape[0])]\n",
    "    hvDF = pd.DataFrame(ngrams.T,columns=hvCols)\n",
    "\n",
    "    # run PCA\n",
    "    featPCA = PCA(n_components=len(featCols))\n",
    "    featResults = featPCA.fit_transform(featDF.values)\n",
    "    hvPCA = PCA(n_components=len(hvCols))\n",
    "    hvResults = hvPCA.fit_transform(hvDF.values)\n",
    "    \n",
    "    matOut['featPCA'] = featResults\n",
    "    matOut['hvPCA'] = hvResults\n",
    "    \n",
    "    featEV = featPCA.explained_variance_ratio_\n",
    "    featEVCum = np.cumsum(featEV)\n",
    "    hvEV = hvPCA.explained_variance_ratio_\n",
    "    hvEVCum = np.cumsum(hvEV)\n",
    "    \n",
    "    matOut['featPCAEV'] = featEV;\n",
    "    matOut['hvPCAEV'] = hvEV;\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.arange(1,len(featEV)+1)/len(featEV),featEV)\n",
    "#     plt.plot(np.arange(1,len(featEV)+1)/len(featEV),featEVCum)\n",
    "#     plt.plot(np.arange(1,len(hvEV)+1)/len(hvEV),hvEV)\n",
    "#     plt.plot(np.arange(1,len(hvEV)+1)/len(hvEV),hvEVCum)\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    # run LDA\n",
    "    featLDA = LDA(n_components=12)\n",
    "    featResults = featLDA.fit_transform(featDF.values,featureLabels)\n",
    "    \n",
    "    matOut['feat'] = features.T\n",
    "    matOut['featLabel'] = featureLabels\n",
    "    matOut['featLDA'] = featResults\n",
    "    \n",
    "    hvLDA = LDA(n_components=12)\n",
    "    hvResults = hvLDA.fit_transform(hvDF.values,ngramLabels)\n",
    "    \n",
    "    matOut['hv'] = ngrams.T\n",
    "    matOut['hvLabel'] = ngramLabels\n",
    "    matOut['hvLDA'] = hvResults\n",
    "    sio.savemat(matFile,matOut)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
